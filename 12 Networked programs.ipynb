{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Finally taking notes in the notebook after 12 chapters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Notes and things"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Notes and code snippets are based off/ from this chapter https://www.py4e.com/html3/12-network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "Sockets can provide two way connection instead of just reading the file. \n",
    "“import socket\n",
    "\n",
    "mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "mysock.connect(('data.pr4e.org', 80))\n",
    "cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()”\n",
    "\n",
    "Excerpt From: Charles R Severance. “Python for Everybody.” Apple Books. \n",
    "\n",
    "connects to to port 80 of the webserver then uses get to request data \\r\\n\\r\\n signifies and eol(end of line) and that there is nothing between the two.\n",
    "\n",
    "Second part of the program \n",
    "“while True:\n",
    "    # gets loops through getting data in 512 char chunks until there is no more\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()\"\n",
    "\n",
    " Code: http://www.py4e.com/code3/socket1.py\n",
    "\n",
    "\n",
    "outputs a header then the data \n",
    "header contains date https version\n",
    "content length, and type, connection .\n",
    "\n",
    "http uses bytes not strings\n",
    "\n",
    "b'insert text' and 'insert text'.encode end up meaning the same thing to store it as a bytes object.\n",
    "\n",
    "time.sleep() can be used to make sure to get 5120 chars per call of rcev and allow server to get ahead\n",
    "three ''' or \"\"\" allows for multi line strings (Also for next chapter)\n",
    "\n",
    "the library urllib can be used to open a webpage like a file it reads the header but doesnt return it back. its possible to make a copy of img or video with urllib. .read(buffer int) makes it so it only reads so many blocks at a time to not use up all avalible ram.\n",
    "\n",
    "can use urrlib to read web pages and look for paterns. to parse with regex could do \"'http[s]?://.+?'\" match the smallest possible matching string\n",
    "\n",
    "ssl library is a thing allowing people to acess websites that strictly enfore https. possible to miss things with regex due to broken html existing\n",
    "however there is an html parssing lib. Ex beautifulSoup:  https://pypi.python.org/pypi/beautifulsoup4\n",
    "\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "# To run this, download the BeautifulSoup zip file\n",
    "# http://www.py4e.com/code3/bs4.zip\n",
    "# and unzip it in the same directory as this file\n",
    "\n",
    "import urllib.request, urllib.parse, urllib.error\n",
    "from bs4 import BeautifulSoup\n",
    "import ssl\n",
    "\n",
    "# Ignore SSL certificate errors\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "url = input('Enter - ')\n",
    "html = urllib.request.urlopen(url, context=ctx).read()\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Retrieve all of the anchor tags\n",
    "tags = soup('a')\n",
    "for tag in tags:\n",
    "    print(tag.get('href', None))\n",
    "\n",
    "# Code: http://www.py4e.com/code3/urllinks.py"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Curl = copy url and retrives binary files\n",
    "wget is similar and both allow for easy retrival of remote files and webpages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Exercises"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Exercise 1: Change the socket program socket1.py to prompt the user for the URL so it can read any web page. You can use split('/') to break the URL into its component parts so you can extract the host name for the socket connect call. Add error checking using try and except to handle the condition where the user enters an improperly formatted or non-existent URL.”\n",
    "\n",
    "Excerpt From: Charles R Severance. “Python for Everybody.” Apple Books. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import socket\n",
    "url = input('give source pls')\n",
    "hostname = url.split\n",
    "print(url)\n",
    "print(hostname)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "raw",
   "source": [
    "try:\n",
    "    mysock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "    mysock.connect((hostname, 80))\n",
    "    cmd = 'GET http://data.pr4e.org/romeo.txt HTTP/1.0\\r\\n\\r\\n'.encode()\n",
    "except:\n",
    "    print('hek')\n",
    "while True:\n",
    "    # gets loops through getting data in 512 char chunks until there is no more\n",
    "    data = mysock.recv(512)\n",
    "    if len(data) < 1:\n",
    "        break\n",
    "    print(data.decode(),end='')\n",
    "\n",
    "mysock.close()"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Exercise 2: Change your socket program so that it counts the number of characters it has received and stops displaying any text after it has shown 3000 characters. The program should retrieve the entire document and count the total number of characters and display the count of the number of characters at the end of the document.”\n",
    "\n",
    "Excerpt From: Charles R Severance. “Python for Everybody.” Apple Books. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Exercise 3: Use urllib to replicate the previous exercise of (1) retrieving the document from a URL, (2) displaying up to 3000 characters, and (3) counting the overall number of characters in the document. Don't worry about the headers for this exercise, simply show the first 3000 characters of the document contents.”\n",
    "\n",
    "Excerpt From: Charles R Severance. “Python for Everybody.” Apple Books. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Exercise 4: Change the urllinks.py program to extract and count paragraph (p) tags from the retrieved HTML document and display the count of the paragraphs as the output of your program. Do not display the paragraph text, only count them. Test your program on several small web pages as well as some larger web pages”\n",
    "\n",
    "Excerpt From: Charles R Severance. “Python for Everybody.” Apple Books. "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "“Exercise 5: (Advanced) Change the socket program so that it only shows data after the headers and a blank line have been received. Remember that recv receives characters (newlines and all), not lines.”\n",
    "\n",
    "Excerpt From: Charles R Severance. “Python for Everybody.” Apple Books. \n",
    "\n",
    "one thinks urllib can be used"
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}